{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e795ca4e",
   "metadata": {},
   "source": [
    "<center><strong><font size=+3>Applications of robust 2D median estimators to HERA data</font></center>\n",
    "<br><br>\n",
    "</center>\n",
    "<center><strong><font size=+2>Matyas Molnar and Bojan Nikolic</font><br></strong></center>\n",
    "<br><center><strong><font size=+1>Astrophysics Group, Cavendish Laboratory, University of Cambridge</font></strong></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb0b498",
   "metadata": {},
   "source": [
    "Reduced version of the [hera_application](https://github.com/matyasmolnar/robstat/blob/main/notebooks/hera_application.ipynb) notebook that looks at visibility and power spectrum results from the geometric median and MAD-clipped + mean estimator. No R functions are called, and larger datasets are considered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8102317f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import multiprocessing\n",
    "import os\n",
    "\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import signal\n",
    "\n",
    "from robstat.hera_vis import agg_tint_rephase\n",
    "from robstat.ml import extrem_nans, nan_interp2d\n",
    "from robstat.plotting import grid_heatmaps, row_heatmaps\n",
    "from robstat.robstat import geometric_median, mv_normality, mv_outlier\n",
    "from robstat.stdstat import mad_clip, rsc_mean\n",
    "from robstat.utils import DATAPATH, flt_nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2913fa9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b5f7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp = True # turn on multiprocessing\n",
    "\n",
    "plot_figs = False\n",
    "if plot_figs:\n",
    "    mpl.rcParams['figure.figsize'] = (12, 8)\n",
    "    mpl.rcParams['figure.dpi'] = 300\n",
    "else:\n",
    "    mpl.rcParams['figure.figsize'] = (5, 3)\n",
    "    mpl.rcParams['figure.dpi'] = 125"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb49aebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# params\n",
    "mad_sigma = 4.0 # sigma threshold for MAD-clipping, default is 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d057f5",
   "metadata": {},
   "source": [
    "### Load HERA visibility data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4693d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xd_vis_file = os.path.join(DATAPATH, 'lstb_no_avg/idr2_b2f2_ee.npz')\n",
    "# xd_vis_file = os.path.join(DATAPATH, 'idr2_xdg/xd_vis_b2f2_ee_rph.npz')\n",
    "xd_vis_file = os.path.join(DATAPATH, 'xd_vis_extd_rph.npz')\n",
    "sample_xd_data = np.load(xd_vis_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a809ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "xd_data = sample_xd_data['data']\n",
    "xd_redg = sample_xd_data['redg']\n",
    "xd_pol = sample_xd_data['pol'].item()\n",
    "\n",
    "if 'lstb_no_avg' in xd_vis_file:\n",
    "    lstb_format = True\n",
    "    # data dimensions (2xdays, freqs, times, bls)\n",
    "    xd_flags = np.isnan(xd_data)\n",
    "    no_chans = xd_data.shape[1]\n",
    "    chans = plt_chans = np.arange(no_chans)\n",
    "    freqs = np.linspace(1e8, 2e8, 1025)[:-1]\n",
    "    new_no_tints = xd_data.shape[2]\n",
    "    \n",
    "else:\n",
    "    lstb_format = False\n",
    "    # data dimensions (days, freqs, times, bls)\n",
    "    xd_flags = sample_xd_data['flags']\n",
    "    xd_data[xd_flags] *= np.nan\n",
    "\n",
    "    xd_redg = sample_xd_data['redg']\n",
    "    xd_pol = sample_xd_data['pol'].item()\n",
    "    xd_rad_lsts = sample_xd_data['lsts']\n",
    "    xd_hr_lsts = xd_rad_lsts*12/np.pi # in hours\n",
    "    no_bins_agg = 2 # averaging over n consecutive time bins in LST averaging\n",
    "    # (2 by default, like in HERA analysis pipeline)\n",
    "    avg_hr_lsts = np.mean(xd_hr_lsts.reshape(-1, no_bins_agg), axis=1)\n",
    "    JDs = sample_xd_data['JDs']\n",
    "\n",
    "    freqs = sample_xd_data['freqs']\n",
    "    chans = sample_xd_data['chans']\n",
    "    if chans[-1]%100 == 99:\n",
    "        plt_chans = np.append(chans, chans[-1]+1)\n",
    "    else:\n",
    "        plt_chans = chans\n",
    "\n",
    "    no_chans = chans.size\n",
    "    no_days = JDs.size\n",
    "    no_tints = xd_rad_lsts.size\n",
    "    new_no_tints = int(np.ceil(no_tints/no_bins_agg))\n",
    "    \n",
    "    if 'rph' in os.path.basename(xd_vis_file) and no_bins_agg > 1:\n",
    "        print('Rephasing visibilities such that every {} rows in time have the same phase centre.'\\\n",
    "              .format(no_bins_agg))\n",
    "        xd_antpos = np.load(xd_vis_file, allow_pickle=True)['antpos'].item()\n",
    "        xd_data = agg_tint_rephase(xd_data, xd_redg, freqs, xd_pol, xd_rad_lsts, xd_antpos, \\\n",
    "                                   no_bins_agg=no_bins_agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1bb253d",
   "metadata": {},
   "outputs": [],
   "source": [
    "myround = lambda x, base=25: base * max(1, round(x/base))\n",
    "tbase = myround(new_no_tints/5)\n",
    "fbase = myround(no_chans/5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c7aa44",
   "metadata": {},
   "outputs": [],
   "source": [
    "bl_grp = 0 # only look at 0th baseline group\n",
    "\n",
    "slct_bl_idxs = np.where(xd_redg[:, 0] == bl_grp)[0]\n",
    "slct_red_bl = xd_redg[slct_bl_idxs[0], :][1:]\n",
    "xd_data_bls = xd_data[..., slct_bl_idxs]\n",
    "no_bls = slct_bl_idxs.size\n",
    "print('Looking at baselines redundant to ({}, {}, \\'{}\\')'.\\\n",
    "      format(*slct_red_bl, xd_pol))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc010a9",
   "metadata": {},
   "source": [
    "### LST + redundant averaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27bec739",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_dir = os.path.join(DATAPATH, 'loc_res_nrao')\n",
    "if not os.path.exists(res_dir):\n",
    "    os.mkdir(res_dir)\n",
    "    \n",
    "lst_red_res_fn = os.path.join(res_dir, os.path.basename(xd_vis_file).replace('.npz', '.lst_red_res.npz'))\n",
    "if not os.path.exists(lst_red_res_fn):\n",
    "    \n",
    "    if mp:\n",
    "        def freq_iter(freq):\n",
    "            xd_gmed_res_f = np.empty((1, new_no_tints), dtype=complex)\n",
    "            xd_hmean_res_f = np.empty_like(xd_gmed_res_f)\n",
    "            \n",
    "            gmed_ft_init = None\n",
    "            for tint in range(new_no_tints):\n",
    "                if lstb_format:\n",
    "                    xd_data_bft = xd_data_bls[:, freq, tint, :].flatten()\n",
    "                else:\n",
    "                    # use no_bins_agg time integrations for each median\n",
    "                    # (2 consecutive ones are used in HERA LST-binning)\n",
    "                    xd_data_bft = xd_data_bls[:, freq, no_bins_agg*tint:no_bins_agg*tint+no_bins_agg, \\\n",
    "                                              :].flatten()\n",
    "\n",
    "                if np.isnan(xd_data_bft).all():\n",
    "                    gmed_ft = hmean_ft = np.nan + 1j*np.nan\n",
    "                else:\n",
    "                    gmed_ft = geometric_median(xd_data_bft, init_guess=gmed_ft_init, keep_res=True)\n",
    "                    gmed_ft_init = gmed_ft\n",
    "                    hmean_ft = rsc_mean(xd_data_bft, sigma=mad_sigma)\n",
    "\n",
    "                xd_gmed_res_f[:, tint] = gmed_ft\n",
    "                xd_hmean_res_f[:, tint] = hmean_ft\n",
    "            return xd_gmed_res_f, xd_hmean_res_f\n",
    "        \n",
    "        m_pool = multiprocessing.Pool(multiprocessing.cpu_count())\n",
    "        gmed_res = np.concatenate(m_pool.map(freq_iter, range(no_chans)), axis=1)\n",
    "        xd_gmed_res = gmed_res[0, ...]\n",
    "        xd_hmean_res = gmed_res[1, ...]        \n",
    "        \n",
    "    else:\n",
    "        xd_gmed_res = np.empty((no_chans, new_no_tints), dtype=complex)\n",
    "        xd_hmean_res = np.empty_like(xd_gmed_res)\n",
    "        \n",
    "        gmed_ft_init = None\n",
    "        for freq in range(no_chans):\n",
    "            for tint in range(new_no_tints):\n",
    "                if lstb_format:\n",
    "                    xd_data_bft = xd_data_bls[:, freq, tint, :].flatten()\n",
    "                else:\n",
    "                    xd_data_bft = xd_data_bls[:, freq, no_bins_agg*tint:no_bins_agg*tint+no_bins_agg, :].flatten()\n",
    "\n",
    "                if np.isnan(xd_data_bft).all():\n",
    "                    gmed_ft = hmean_ft = np.nan + 1j*np.nan\n",
    "                else:\n",
    "                    gmed_ft = geometric_median(xd_data_bft, init_guess=gmed_ft_init, keep_res=True)\n",
    "                    gmed_ft_init = gmed_ft\n",
    "                    hmean_ft = rsc_mean(xd_data_bft, sigma=mad_sigma)\n",
    "\n",
    "                xd_gmed_res[freq, tint] = gmed_ft\n",
    "                xd_hmean_res[freq, tint] = hmean_ft\n",
    "            \n",
    "    np.savez(lst_red_res_fn, xd_gmed_res=xd_gmed_res, xd_hmean_res=xd_hmean_res)\n",
    "\n",
    "else:\n",
    "    lst_red_res = np.load(lst_red_res_fn)\n",
    "    xd_gmed_res = lst_red_res['xd_gmed_res']\n",
    "    xd_hmean_res = lst_red_res['xd_hmean_res']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79ad096",
   "metadata": {},
   "outputs": [],
   "source": [
    "arrs = [xd_gmed_res, xd_hmean_res]\n",
    "\n",
    "tr_arrs = lambda x, np_fn: [getattr(np, np_fn)(i) for i in x]\n",
    "garrs = [tr_arrs(arrs, 'abs'), tr_arrs(arrs, 'angle'), tr_arrs(arrs, 'real'), tr_arrs(arrs, 'imag')]\n",
    "garrs = [[arr[i] for arr in garrs] for i in range(len(garrs[0]))]\n",
    "\n",
    "titles = ['Geometric Median', 'HERA Mean']\n",
    "ylabels = ['Amp', 'Phase', r'$\\mathfrak{Re}$', r'$\\mathfrak{Im}$']\n",
    "ylabels = [ylab + '\\n\\nFrequency channel' for ylab in ylabels]\n",
    "\n",
    "grid_heatmaps(garrs, titles=titles, figsize=(8, 10), xbase=tbase, ybase=fbase, clip_pctile=1, \\\n",
    "              xlabels='Time bin', yticklabels=plt_chans, ylabels=ylabels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f3a149",
   "metadata": {},
   "source": [
    "#### Smoothness of median results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e7f704",
   "metadata": {},
   "source": [
    "Calculate standard deviation of the distances between successive points in either frequency or time to get an idea of the smoothness of the location results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee968cf",
   "metadata": {},
   "source": [
    "##### Standard deviation of absolute distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75dcef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in time\n",
    "t_smoothness = []\n",
    "for arr in arrs:\n",
    "    t_stds = np.empty(arr.shape[0])\n",
    "    for f in range(arr.shape[0]):\n",
    "        dists = np.abs(np.ediff1d(arr[f, :]))\n",
    "        t_stds[f] = np.nanstd(dists)\n",
    "    t_smoothness.append(np.nanmean(t_stds))\n",
    "print('Smoothness in time: \\n{}\\n{}\\n'.format(titles, t_smoothness))\n",
    "\n",
    "# in frequency\n",
    "f_smoothness = []\n",
    "for arr in arrs:\n",
    "    f_stds = np.empty(arr.shape[1])\n",
    "    for t in range(arr.shape[1]):\n",
    "        dists = np.abs(np.ediff1d(arr[:, t]))\n",
    "        f_stds[t] = np.nanstd(dists)\n",
    "    f_smoothness.append(np.nanmean(f_stds))\n",
    "print('Smoothness in frequency: \\n{}\\n{}'.format(titles, f_smoothness))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43a7536",
   "metadata": {},
   "source": [
    "##### Standard deviation of complex differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb699276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in time\n",
    "t_smoothness = []\n",
    "for arr in arrs:\n",
    "    t_stds = np.empty(arr.shape[0])\n",
    "    for f in range(arr.shape[0]):\n",
    "        dists = np.ediff1d(arr[f, :])\n",
    "        t_stds[f] = np.nanstd(dists)\n",
    "    t_smoothness.append(np.nanmean(t_stds))\n",
    "print('Smoothness in time: \\n{}\\n{}\\n'.format(titles, t_smoothness))\n",
    "\n",
    "# in frequency\n",
    "f_smoothness = []\n",
    "for arr in arrs:\n",
    "    f_stds = np.empty(arr.shape[1])\n",
    "    for t in range(arr.shape[1]):\n",
    "        dists = np.ediff1d(arr[:, t])\n",
    "        f_stds[t] = np.nanstd(dists)\n",
    "    f_smoothness.append(np.nanmean(f_stds))\n",
    "print('Smoothness in frequency: \\n{}\\n{}'.format(titles, f_smoothness))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f884cbdd",
   "metadata": {},
   "source": [
    "### Interpolation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6469136",
   "metadata": {},
   "source": [
    "#### Visualize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243ad547",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(ncols=2, nrows=2, figsize=(7, 5), sharey='row', sharex='col')\n",
    "\n",
    "axes[0][0].plot(np.abs(xd_gmed_res), alpha=0.7)\n",
    "axes[0][1].plot(np.abs(xd_hmean_res), alpha=0.7)\n",
    "axes[1][0].plot(np.angle(xd_gmed_res), alpha=0.7)\n",
    "axes[1][1].plot(np.angle(xd_hmean_res), alpha=0.7)\n",
    "\n",
    "axes[0][0].set_ylabel(r'$|V|$')\n",
    "axes[1][0].set_ylabel(r'$\\varphi$')\n",
    "\n",
    "axes[1][0].set_xlabel('Frequency channel')\n",
    "axes[1][1].set_xlabel('Frequency channel')\n",
    "\n",
    "axes[0][0].set_title('Geometric Median')\n",
    "axes[0][1].set_title('HERA Mean')\n",
    "\n",
    "for axr in axes:\n",
    "    for axc in axr:\n",
    "        axc.set_xticks(np.arange(plt_chans.size)[::fbase])\n",
    "        axc.set_xticklabels(plt_chans[::fbase])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a81ba0",
   "metadata": {},
   "source": [
    "#### Fill in gaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d818f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "band_1 = [175, 334]\n",
    "band_2 = [515, 694]\n",
    "\n",
    "band_i = band_1 # select band here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85121794",
   "metadata": {},
   "outputs": [],
   "source": [
    "if lstb_format:\n",
    "    gmed_flt = xd_gmed_res[band_i[0]:band_i[1]+1, :]\n",
    "    hmean_flt = xd_hmean_res[band_i[0]:band_i[1]+1, :]\n",
    "    flt_chans = chans.copy()[band_i[0]:band_i[1]+1]\n",
    "    fbase = 25\n",
    "else:\n",
    "    gmed_flt = xd_gmed_res\n",
    "    hmean_flt = xd_hmean_res\n",
    "    flt_chans = chans\n",
    "\n",
    "# grid interpolation to replace nan values\n",
    "gmed_interp2 = nan_interp2d(gmed_flt)\n",
    "hmean_interp2 = nan_interp2d(hmean_flt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01636d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_chans = extrem_nans(np.isnan(xd_gmed_res[band_i[0]:band_i[1]+1, :]).all(axis=1))\n",
    "if nan_chans.size != 0:\n",
    "    flt_chans = np.delete(flt_chans, nan_chans, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10bec99",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(ncols=2, nrows=2, figsize=(7, 5), sharey='row', sharex='col')\n",
    "\n",
    "axes[0][0].plot(np.abs(gmed_interp2), alpha=0.7)\n",
    "axes[0][1].plot(np.abs(hmean_interp2), alpha=0.7)\n",
    "axes[1][0].plot(np.angle(gmed_interp2), alpha=0.7)\n",
    "axes[1][1].plot(np.angle(hmean_interp2), alpha=0.7)\n",
    "\n",
    "axes[0][0].set_ylabel(r'$|V|$')\n",
    "axes[1][0].set_ylabel(r'$\\varphi$')\n",
    "\n",
    "axes[1][0].set_xlabel('Frequency channel')\n",
    "axes[1][1].set_xlabel('Frequency channel')\n",
    "\n",
    "axes[0][0].set_title('Geometric Median')\n",
    "axes[0][1].set_title('HERA Mean')\n",
    "\n",
    "for axr in axes:\n",
    "    for axc in axr:\n",
    "        axc.set_xticks(np.arange(flt_chans.size)[::fbase])\n",
    "        axc.set_xticklabels(flt_chans[::fbase])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2a2c8c",
   "metadata": {},
   "source": [
    "### Power spectrum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6687d76",
   "metadata": {},
   "source": [
    "#### All time integrations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f6c9ab",
   "metadata": {},
   "source": [
    "Incoherrent averaging in time only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a088eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_resolution = np.median(np.ediff1d(freqs))\n",
    "\n",
    "gmed_delay, gmed_pspec = signal.periodogram(gmed_interp2, fs=1/f_resolution, \\\n",
    "    window='hann', scaling='spectrum', nfft=None, detrend=False, \\\n",
    "    return_onesided=False, axis=0)\n",
    "\n",
    "delay_sort = np.argsort(gmed_delay)\n",
    "gmed_delay = gmed_delay[delay_sort]\n",
    "gmed_pspec = gmed_pspec[delay_sort, :]\n",
    "\n",
    "hmean_delay, hmean_pspec = signal.periodogram(hmean_interp2, fs=1/f_resolution, \\\n",
    "    window='hann', scaling='spectrum', nfft=None, detrend=False, \\\n",
    "    return_onesided=False, axis=0)\n",
    "\n",
    "delay_sort = np.argsort(hmean_delay)\n",
    "hmean_delay = hmean_delay[delay_sort]\n",
    "hmean_pspec = hmean_pspec[delay_sort, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a7ef8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(ncols=3, figsize=(8, 5), sharey=True)\n",
    "\n",
    "axes[0].plot(gmed_delay, gmed_pspec, alpha=0.3)\n",
    "axes[0].plot(gmed_delay, gmed_pspec.mean(axis=1), alpha=1, color='orange')\n",
    "axes[0].set_ylabel('Power spectrum')\n",
    "\n",
    "axes[1].plot(hmean_delay, hmean_pspec, alpha=0.3)\n",
    "axes[1].plot(hmean_delay, hmean_pspec.mean(axis=1), alpha=1, color='purple')\n",
    "\n",
    "axes[2].plot(gmed_delay, gmed_pspec.mean(axis=1), alpha=0.7, color='orange', label='Geometric Median')\n",
    "axes[2].plot(hmean_delay, hmean_pspec.mean(axis=1), alpha=0.7, color='purple', label='HERA Mean')\n",
    "\n",
    "for ax in axes:\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_xlabel('Delay')\n",
    "    \n",
    "axes[0].set_title('Geometric Median')\n",
    "axes[1].set_title('HERA Mean')\n",
    "axes[2].set_title('Comparison')\n",
    "axes[2].legend(loc='best', prop={'size': 8})\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854b52ad",
   "metadata": {},
   "source": [
    "#### Only average visibilities across days\n",
    "\n",
    "And further average across baselines post power spectrum computation by computing cross-power spectrum across all baseline permutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2db76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove baselines with only nan entries\n",
    "nan_bls = np.where(np.isnan(xd_data_bls).all(axis=(0, 1, 2)))[0]\n",
    "flt_no_bls = no_bls - nan_bls.size\n",
    "xd_data_bls_flt = np.delete(xd_data_bls, nan_bls, axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a7217d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_full_res_fn = os.path.join(res_dir, os.path.basename(xd_vis_file).replace('.npz', '.lst_full_res.npz'))\n",
    "\n",
    "if not os.path.exists(lst_full_res_fn):\n",
    "\n",
    "    if mp:\n",
    "        def bl_iter(bl):\n",
    "            xd_gmed_res_b = np.empty((no_chans, new_no_tints, 1), dtype=complex)\n",
    "            xd_hmean_res_b = np.empty_like(xd_gmed_res_b)\n",
    "            \n",
    "            gmed_ft_init = None\n",
    "            for freq in range(no_chans):\n",
    "                for tint in range(new_no_tints):\n",
    "                    if lstb_format:\n",
    "                        xd_data_bft = xd_data_bls_flt[:, freq, tint, bl].flatten()\n",
    "                    else:\n",
    "                        # use no_bins_agg time integrations for each median\n",
    "                        # (2 consecutive ones are used in HERA LST-binning)\n",
    "                        xd_data_bft = xd_data_bls_flt[:, freq, no_bins_agg*tint:no_bins_agg*tint+no_bins_agg, \\\n",
    "                                                      bl].flatten()\n",
    "\n",
    "                    if np.isnan(xd_data_bft).all():\n",
    "                        gmed_ft = hmean_ft = np.nan + 1j*np.nan\n",
    "                    else:\n",
    "                        gmed_ft = geometric_median(xd_data_bft, init_guess=gmed_ft_init, keep_res=True)\n",
    "                        gmed_ft_init = gmed_ft\n",
    "                        hmean_ft = rsc_mean(xd_data_bft, sigma=mad_sigma)\n",
    "\n",
    "                    xd_gmed_res_b[freq, tint, :] = gmed_ft\n",
    "                    xd_hmean_res_b[freq, tint, :] = hmean_ft\n",
    "                    \n",
    "            return xd_gmed_res_b, xd_hmean_res_b\n",
    "        \n",
    "        m_pool = multiprocessing.Pool(multiprocessing.cpu_count())\n",
    "        x = m_pool.map(bl_iter, range(flt_no_bls))\n",
    "        gmed_res = np.concatenate(m_pool.map(bl_iter, range(flt_no_bls)), axis=3)\n",
    "        xd_gmed_res_bl = gmed_res[0, ...]\n",
    "        xd_hmean_res_bl = gmed_res[1, ...]      \n",
    "        \n",
    "    else:\n",
    "        xd_gmed_res_bl = np.empty((no_chans, new_no_tints, flt_no_bls), dtype=complex)\n",
    "        xd_hmean_res_bl = np.empty_like(xd_gmed_res_bl)\n",
    "        \n",
    "        gmed_ft_init = None\n",
    "        for bl in range(flt_no_bls):\n",
    "            for freq in range(no_chans):\n",
    "                for tint in range(new_no_tints):\n",
    "                    if lstb_format:\n",
    "                        xd_data_bft = xd_data_bls_flt[:, freq, tint, bl].flatten()\n",
    "                    else:\n",
    "                        xd_data_bft = xd_data_bls_flt[:, freq, no_bins_agg*tint:no_bins_agg*tint+no_bins_agg, \\\n",
    "                                                      bl].flatten()\n",
    "                    if np.isnan(xd_data_bft).all():\n",
    "                        gmed_ft = hmean_ft = np.nan + 1j*np.nan\n",
    "                    else:\n",
    "                        gmed_ft = geometric_median(xd_data_bft, init_guess=gmed_ft_init, \\\n",
    "                                                   keep_res=True)\n",
    "                        gmed_ft_init = gmed_ft\n",
    "                        hmean_ft = rsc_mean(xd_data_bft, sigma=mad_sigma)\n",
    "                    xd_gmed_res_bl[freq, tint, bl] = gmed_ft\n",
    "                    xd_hmean_res_bl[freq, tint, bl] = hmean_ft\n",
    "                \n",
    "    np.savez(lst_full_res_fn, xd_gmed_res_bl=xd_gmed_res_bl, xd_hmean_res_bl=xd_hmean_res_bl)\n",
    "\n",
    "else:\n",
    "    red_res = np.load(lst_full_res_fn)\n",
    "    xd_gmed_res_bl = red_res['xd_gmed_res_bl']\n",
    "    xd_hmean_res_bl = red_res['xd_hmean_res_bl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf3e62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the visibility location estimates for a selected time slice\n",
    "fig, axes = plt.subplots(ncols=2, nrows=2, figsize=(7, 5), sharey='row', sharex='col')\n",
    "\n",
    "slct_tint = 0\n",
    "\n",
    "axes[0][0].plot(np.abs(xd_gmed_res_bl[:, slct_tint, :]), alpha=0.7)\n",
    "axes[0][1].plot(np.abs(xd_hmean_res_bl[:, slct_tint, :]), alpha=0.7)\n",
    "axes[1][0].plot(np.angle(xd_gmed_res_bl[:, slct_tint, :]), alpha=0.7)\n",
    "axes[1][1].plot(np.angle(xd_hmean_res_bl[:, slct_tint, :]), alpha=0.7)\n",
    "\n",
    "axes[0][0].set_ylabel(r'$|V|$')\n",
    "axes[1][0].set_ylabel(r'$\\varphi$')\n",
    "\n",
    "axes[1][0].set_xlabel('Frequency channel')\n",
    "axes[1][1].set_xlabel('Frequency channel')\n",
    "\n",
    "axes[0][0].set_title('Geometric Median')\n",
    "axes[0][1].set_title('HERA Mean')\n",
    "\n",
    "for axr in axes:\n",
    "    for axc in axr:\n",
    "        axc.set_xticks(np.arange(plt_chans.size)[::fbase])\n",
    "        axc.set_xticklabels(plt_chans[::fbase])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fcedab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D interpolation for each baseline separately\n",
    "gmed_interp_bl_list = []\n",
    "hmean_interp_bl_list = []\n",
    "nan_idxs_f = []\n",
    "nan_idxs_t = []\n",
    "\n",
    "if lstb_format:\n",
    "    gmed_flt_bl = xd_gmed_res_bl[band_i[0]:band_i[1]+1, ...]\n",
    "    hmean_flt_bl = xd_hmean_res_bl[band_i[0]:band_i[1]+1, ...]\n",
    "else:\n",
    "    gmed_flt_bl = xd_gmed_res_bl\n",
    "    hmean_flt_bl = xd_hmean_res_bl\n",
    "\n",
    "for bl in range(flt_no_bls):\n",
    "    gmed_i, gmed_nidxf, gmed_nidxt = nan_interp2d(gmed_flt_bl[..., bl], rtn_nan_idxs=True)\n",
    "    hmean_i, hmean_nidxf, hmean_nidxt = nan_interp2d(hmean_flt_bl[..., bl], rtn_nan_idxs=True)\n",
    "    gmed_interp_bl_list.append(gmed_i)\n",
    "    hmean_interp_bl_list.append(hmean_i)\n",
    "    nan_idxs_f.append(gmed_nidxf)\n",
    "    nan_idxs_f.append(hmean_nidxf)\n",
    "    nan_idxs_t.append(gmed_nidxt)\n",
    "    nan_idxs_t.append(hmean_nidxt)\n",
    "    \n",
    "if np.unique(nan_idxs_f).size != 0:\n",
    "    gmed_interp_bl_list = [np.delete(gmed_i, np.unique(nan_idxs_f), axis=0) for gmed_i in gmed_interp_bl_list]\n",
    "    hmean_interp_bl_list = [np.delete(hmean_i, np.unique(nan_idxs_f), axis=0) for hmean_i in hmean_interp_bl_list]\n",
    "    \n",
    "if np.unique(nan_idxs_t).size != 0:\n",
    "    gmed_interp_bl_list = [np.delete(gmed_i, np.unique(nan_idxs_t), axis=1) for gmed_i in gmed_interp_bl_list]\n",
    "    hmean_interp_bl_list = [np.delete(hmean_i, np.unique(nan_idxs_t), axis=1) for hmean_i in hmean_interp_bl_list]\n",
    "    \n",
    "gmed_interp2_bl = np.moveaxis(np.array(gmed_interp_bl_list), 0, 2)\n",
    "hmean_interp2_bl = np.moveaxis(np.array(hmean_interp_bl_list), 0, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfbc17c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "bl_idx_plt = 0\n",
    "\n",
    "fig, axes = plt.subplots(ncols=2, nrows=2, figsize=(7, 5), sharey='row', sharex='col')\n",
    "\n",
    "axes[0][0].plot(np.abs(gmed_interp2_bl[..., bl_idx_plt]), alpha=0.7)\n",
    "axes[0][1].plot(np.abs(hmean_interp2_bl[..., bl_idx_plt]), alpha=0.7)\n",
    "axes[1][0].plot(np.angle(gmed_interp2_bl[..., bl_idx_plt]), alpha=0.7)\n",
    "axes[1][1].plot(np.angle(hmean_interp2_bl[..., bl_idx_plt]), alpha=0.7)\n",
    "\n",
    "axes[0][0].set_ylabel(r'$|V|$')\n",
    "axes[1][0].set_ylabel(r'$\\varphi$')\n",
    "\n",
    "axes[1][0].set_xlabel('Frequency channel')\n",
    "axes[1][1].set_xlabel('Frequency channel')\n",
    "\n",
    "axes[0][0].set_title('Geometric Median')\n",
    "axes[0][1].set_title('HERA Mean')\n",
    "\n",
    "for axr in axes:\n",
    "    for axc in axr:\n",
    "        axc.set_xticks(np.arange(flt_chans.size)[::fbase])\n",
    "        axc.set_xticklabels(flt_chans[::fbase])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee0da03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross-PS between all baseline pairs\n",
    "bl_pairs = list(itertools.permutations(np.arange(flt_no_bls), r=2))\n",
    "bls1 = [i[0] for i in bl_pairs]\n",
    "bls2 = [i[1] for i in bl_pairs]\n",
    "\n",
    "gmed_delay, gmed_pspec = signal.csd(gmed_interp2_bl[..., bls1], gmed_interp2_bl[..., bls2], \\\n",
    "    fs=1/f_resolution, window='hann', scaling='spectrum', nfft=None, detrend=False, \\\n",
    "    return_onesided=False, nperseg=gmed_interp2_bl.shape[0], axis=0)\n",
    "\n",
    "delay_sort = np.argsort(gmed_delay)\n",
    "gmed_delay = gmed_delay[delay_sort]\n",
    "gmed_pspec = gmed_pspec[delay_sort, :]\n",
    "\n",
    "hmean_delay, hmean_pspec = signal.csd(hmean_interp2_bl[..., bls1], hmean_interp2_bl[..., bls2], \\\n",
    "    fs=1/f_resolution, window='hann', scaling='spectrum', nfft=None, detrend=False, \\\n",
    "    return_onesided=False, nperseg=hmean_interp2_bl.shape[0], axis=0)\n",
    "\n",
    "delay_sort = np.argsort(hmean_delay)\n",
    "hmean_delay = hmean_delay[delay_sort]\n",
    "hmean_pspec = hmean_pspec[delay_sort, :]\n",
    "\n",
    "gmed_pspec = np.nanmean(gmed_pspec, axis=2)\n",
    "hmean_pspec = np.nanmean(hmean_pspec, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f31eee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(ncols=3, figsize=(8, 5), sharey=True)\n",
    "\n",
    "axes[0].plot(gmed_delay, np.abs(gmed_pspec), alpha=0.3)\n",
    "axes[0].plot(gmed_delay, np.abs(gmed_pspec.mean(axis=1)), alpha=1, color='orange')\n",
    "axes[0].set_ylabel('Power spectrum')\n",
    "\n",
    "axes[1].plot(hmean_delay, np.abs(hmean_pspec), alpha=0.3)\n",
    "axes[1].plot(hmean_delay, np.abs(hmean_pspec.mean(axis=1)), alpha=1, color='purple')\n",
    "\n",
    "# average over times\n",
    "axes[2].plot(gmed_delay, np.abs(gmed_pspec.mean(axis=1)), alpha=0.6, color='orange', label='Geometric Median')\n",
    "axes[2].plot(hmean_delay, np.abs(hmean_pspec.mean(axis=1)), alpha=0.6, color='purple', label='HERA Mean')\n",
    "\n",
    "for ax in axes:\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_xlabel('Delay')\n",
    "    \n",
    "axes[0].set_title('Geometric Median')\n",
    "axes[1].set_title('HERA Mean')\n",
    "axes[2].set_title('Comparison')\n",
    "axes[2].legend(loc='best', prop={'size': 8})\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e876a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dly_lim = 1.5e-6\n",
    "high_dlys = np.where(np.abs(gmed_delay) >= dly_lim)\n",
    "resid = (np.abs(gmed_pspec.mean(axis=1)) - np.abs(hmean_pspec.mean(axis=1)))[high_dlys]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7, 5))\n",
    "ax.scatter(gmed_delay[high_dlys], resid, s=4, alpha=0.8, label='GM - HM residual')\n",
    "ax.axhline(np.mean(resid), ls='--', color='orange', label='Mean residual')\n",
    "ax.axvspan(-dly_lim, dly_lim, alpha=0.4, color='grey')\n",
    "ax.ticklabel_format(axis='both', style='sci', scilimits=(0, 0))\n",
    "ax.set_xlabel('Delay')\n",
    "ax.set_ylabel('PS residual')\n",
    "ax.legend(loc='upper right', prop={'size': 8})\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "robstat",
   "language": "python",
   "name": "robstat"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
