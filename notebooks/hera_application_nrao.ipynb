{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e795ca4e",
   "metadata": {},
   "source": [
    "<center><strong><font size=+3>Applications of robust 2D median estimators to HERA data</font></center>\n",
    "<br><br>\n",
    "</center>\n",
    "<center><strong><font size=+2>Matyas Molnar and Bojan Nikolic</font><br></strong></center>\n",
    "<br><center><strong><font size=+1>Astrophysics Group, Cavendish Laboratory, University of Cambridge</font></strong></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb0b498",
   "metadata": {},
   "source": [
    "Reduced version of the [hera_application](https://github.com/matyasmolnar/robstat/blob/main/notebooks/hera_application.ipynb) notebook that looks at visibility and power spectrum results from the geometric median and MAD-clipped + mean estimator. No R functions are called, and larger datasets are considered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8102317f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import os\n",
    "\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import signal\n",
    "\n",
    "from robstat.hera_vis import agg_tint_rephase\n",
    "from robstat.ml import extrem_nans, nan_interp2d\n",
    "from robstat.plotting import grid_heatmaps, row_heatmaps\n",
    "from robstat.robstat import geometric_median, mv_normality, mv_outlier\n",
    "from robstat.stdstat import mad_clip, rsc_mean\n",
    "from robstat.utils import DATAPATH, flt_nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2913fa9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b5f7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_figs = False\n",
    "if plot_figs:\n",
    "    mpl.rcParams['figure.figsize'] = (12, 8)\n",
    "    mpl.rcParams['figure.dpi'] = 300\n",
    "else:\n",
    "    mpl.rcParams['figure.figsize'] = (5, 3)\n",
    "    mpl.rcParams['figure.dpi'] = 125"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb49aebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# params\n",
    "mad_sigma = 4.0 # sigma threshold for MAD-clipping, default is 4\n",
    "no_bins_agg = 2 # averaging over n consecutive time bins in LST averaging\n",
    "# (2 by default, like in HERA analysis pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d057f5",
   "metadata": {},
   "source": [
    "### Load HERA visibility data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4693d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "xd_vis_file = os.path.join(DATAPATH, 'xd_vis_extd_rph.npz')\n",
    "sample_xd_data = np.load(xd_vis_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a809ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "xd_data = sample_xd_data['data'] # dimensions (days, freqs, times, bls)\n",
    "xd_flags = sample_xd_data['flags']\n",
    "xd_data[xd_flags] = np.nan\n",
    "\n",
    "xd_redg = sample_xd_data['redg']\n",
    "xd_times = sample_xd_data['times']\n",
    "xd_pol = sample_xd_data['pol'].item()\n",
    "xd_rad_lsts = sample_xd_data['lsts']\n",
    "xd_hr_lsts = xd_rad_lsts*12/np.pi # in hours\n",
    "avg_hr_lsts = np.mean(xd_hr_lsts.reshape(-1, no_bins_agg), axis=1)\n",
    "JDs = sample_xd_data['JDs']\n",
    "\n",
    "freqs = sample_xd_data['freqs']\n",
    "chans = sample_xd_data['chans']\n",
    "if chans[-1]%100 == 99:\n",
    "    plt_chans = np.append(chans, chans[-1]+1)\n",
    "else:\n",
    "    plt_chans = chans\n",
    "\n",
    "no_chans = chans.size\n",
    "no_days = JDs.size\n",
    "no_tints = xd_times.size\n",
    "new_no_tints = int(np.ceil(no_tints/no_bins_agg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19841c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rephase if averaging over consecutive time bins\n",
    "if 'rph' in os.path.basename(xd_vis_file) and no_bins_agg > 1:\n",
    "    print('Rephasing visibilities such that every {} rows in time have the same phase centre.'.format(no_bins_agg))\n",
    "    xd_antpos = np.load(xd_vis_file, allow_pickle=True)['antpos'].item()\n",
    "    xd_data = agg_tint_rephase(xd_data, xd_redg, freqs, xd_pol, xd_rad_lsts, xd_antpos, \\\n",
    "                               no_bins_agg=no_bins_agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c7aa44",
   "metadata": {},
   "outputs": [],
   "source": [
    "bl_grp = 0 # only look at 0th baseline group\n",
    "\n",
    "slct_bl_idxs = np.where(xd_redg[:, 0] == bl_grp)[0]\n",
    "data = xd_data[..., slct_bl_idxs]\n",
    "flags = xd_flags[..., slct_bl_idxs]\n",
    "slct_red_bl = xd_redg[slct_bl_idxs[0], :][1:]\n",
    "xd_data_bls = xd_data[..., slct_bl_idxs]\n",
    "no_bls = slct_bl_idxs.size\n",
    "print('Looking at baselines redundant to ({}, {}, \\'{}\\')'.\\\n",
    "      format(*slct_red_bl, xd_pol))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc010a9",
   "metadata": {},
   "source": [
    "### LST + redundant averaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27bec739",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_dir = os.path.join(DATAPATH, 'loc_res_nrao')\n",
    "if not os.path.exists(res_dir):\n",
    "    os.mkdir(res_dir)\n",
    "    \n",
    "lst_red_res_fn = os.path.join(res_dir, os.path.basename(xd_vis_file).replace('.npz', '.lst_red_res.npz'))\n",
    "if not os.path.exists(lst_red_res_fn):\n",
    "\n",
    "    xd_gmed_res = np.empty((no_chans, new_no_tints), dtype=complex)\n",
    "    xd_hmean_res = np.empty_like(xd_gmed_res)\n",
    "\n",
    "    gmed_ij = None\n",
    "    for freq in range(no_chans):\n",
    "        for tint in range(new_no_tints):\n",
    "            # use no_bins_agg time integrations for each median (2 consecutive ones are used in HERA LST-binning)\n",
    "            xd_data_bft = xd_data_bls[:, freq, no_bins_agg*tint:no_bins_agg*tint+no_bins_agg, :].flatten()\n",
    "            if np.isnan(xd_data_bft).all():\n",
    "                gmed_ft = hmean_ft = np.nan\n",
    "            else:\n",
    "                gmed_ft = geometric_median(xd_data_bft, init_guess=gmed_ij, keep_res=True)\n",
    "                hmean_ft = rsc_mean(xd_data_bft, sigma=mad_sigma)\n",
    "            xd_gmed_res[freq, tint] = gmed_ft\n",
    "            xd_hmean_res[freq, tint] = hmean_ft\n",
    "            \n",
    "    np.savez(lst_red_res_fn, xd_gmed_res=xd_gmed_res, xd_hmean_res=xd_hmean_res)\n",
    "\n",
    "else:\n",
    "    lst_red_res = np.load(lst_red_res_fn)\n",
    "    xd_gmed_res = lst_red_res['xd_gmed_res']\n",
    "    xd_hmean_res = lst_red_res['xd_hmean_res']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79ad096",
   "metadata": {},
   "outputs": [],
   "source": [
    "arrs = [xd_gmed_res, xd_hmean_res]\n",
    "\n",
    "tr_arrs = lambda x, np_fn: [getattr(np, np_fn)(i) for i in x]\n",
    "garrs = [tr_arrs(arrs, 'abs'), tr_arrs(arrs, 'angle'), tr_arrs(arrs, 'real'), tr_arrs(arrs, 'imag')]\n",
    "garrs = [[arr[i] for arr in garrs] for i in range(len(garrs[0]))]\n",
    "\n",
    "titles = ['Geometric Median', 'HERA Mean']\n",
    "ylabels = ['Amp', 'Phase', r'$\\mathfrak{Re}$', r'$\\mathfrak{Im}$']\n",
    "ylabels = [ylab + '\\n\\nFrequency channel' for ylab in ylabels]\n",
    "\n",
    "grid_heatmaps(garrs, titles=titles, figsize=(8, 8), ybase=25, clip_pctile=1, \\\n",
    "              xlabels='Time bin', yticklabels=plt_chans, ylabels=ylabels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f3a149",
   "metadata": {},
   "source": [
    "#### Smoothness of median results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e7f704",
   "metadata": {},
   "source": [
    "Calculate standard deviation of the distances between successive points in either frequency or time to get an idea of the smoothness of the location results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee968cf",
   "metadata": {},
   "source": [
    "##### Standard deviation of absolute distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75dcef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in time\n",
    "t_smoothness = []\n",
    "for arr in arrs:\n",
    "    t_stds = np.empty(arr.shape[0])\n",
    "    for f in range(arr.shape[0]):\n",
    "        dists = np.abs(np.ediff1d(arr[f, :]))\n",
    "        t_stds[f] = np.nanstd(dists)\n",
    "    t_smoothness.append(np.nanmean(t_stds))\n",
    "print('Smoothness in time: \\n{}\\n{}\\n'.format(titles, t_smoothness))\n",
    "\n",
    "# in frequency\n",
    "f_smoothness = []\n",
    "for arr in arrs:\n",
    "    f_stds = np.empty(arr.shape[1])\n",
    "    for t in range(arr.shape[1]):\n",
    "        dists = np.abs(np.ediff1d(arr[:, t]))\n",
    "        f_stds[t] = np.nanstd(dists)\n",
    "    f_smoothness.append(np.nanmean(f_stds))\n",
    "print('Smoothness in frequency: \\n{}\\n{}'.format(titles, f_smoothness))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43a7536",
   "metadata": {},
   "source": [
    "##### Standard deviation of complex differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb699276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in time\n",
    "t_smoothness = []\n",
    "for arr in arrs:\n",
    "    t_stds = np.empty(arr.shape[0])\n",
    "    for f in range(arr.shape[0]):\n",
    "        dists = np.ediff1d(arr[f, :])\n",
    "        t_stds[f] = np.nanstd(dists)\n",
    "    t_smoothness.append(np.nanmean(t_stds))\n",
    "print('Smoothness in time: \\n{}\\n{}\\n'.format(titles, t_smoothness))\n",
    "\n",
    "# in frequency\n",
    "f_smoothness = []\n",
    "for arr in arrs:\n",
    "    f_stds = np.empty(arr.shape[1])\n",
    "    for t in range(arr.shape[1]):\n",
    "        dists = np.ediff1d(arr[:, t])\n",
    "        f_stds[t] = np.nanstd(dists)\n",
    "    f_smoothness.append(np.nanmean(f_stds))\n",
    "print('Smoothness in frequency: \\n{}\\n{}'.format(titles, f_smoothness))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c141f87",
   "metadata": {},
   "source": [
    "### Test of normality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb612d7",
   "metadata": {},
   "source": [
    "#### Henze-Zirkler multivariate normality test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418e4e02",
   "metadata": {},
   "source": [
    "We use the HZ test as this considers the entirety of the data. Note that many alternatives tests also exist and that a single statistic does not definitely conclude if the multivariate data is normality distributed or not. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c46c8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAD-clipping about Re and Im separately, like HERA\n",
    "nan_flags = np.isnan(xd_data_bls)\n",
    "re_clip_f = mad_clip(xd_data_bls.real, axis=(0, 3), flags=nan_flags, verbose=True)[1]\n",
    "im_clip_f = mad_clip(xd_data_bls.imag, axis=(0, 3), flags=nan_flags, verbose=True)[1]\n",
    "\n",
    "xd_data_bls_c = xd_data_bls.copy()\n",
    "xd_data_bls_c[re_clip_f + im_clip_f] *= np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b647b254",
   "metadata": {},
   "outputs": [],
   "source": [
    "mv_nrm_res_fn = os.path.join(res_dir, os.path.basename(xd_vis_file).replace('.npz', '.mv_nrm_res.npz'))\n",
    "\n",
    "if not os.path.exists(mv_nrm_res_fn):\n",
    "\n",
    "    hz_r = np.empty_like(xd_gmed_res, dtype=float)\n",
    "    hz_p = np.empty_like(hz_r)\n",
    "    hz_n = np.empty_like(hz_r, dtype=bool)\n",
    "\n",
    "    hz_r_c = np.empty_like(hz_r)\n",
    "    hz_p_c = np.empty_like(hz_r)\n",
    "    hz_n_c = np.empty_like(hz_n)\n",
    "\n",
    "    bool_dict = {'NO': False, 'YES': True, np.nan: False}\n",
    "\n",
    "    for freq in range(no_chans):\n",
    "        for tint in range(new_no_tints):\n",
    "            xd_data_bft = flt_nan(xd_data_bls[:, freq, no_bins_agg*tint:no_bins_agg*tint+no_bins_agg, \\\n",
    "                                              :].flatten())\n",
    "            xd_data_bcft = flt_nan(xd_data_bls_c[:, freq, no_bins_agg*tint:no_bins_agg*tint+no_bins_agg, \\\n",
    "                                                 :].flatten())\n",
    "\n",
    "            hz_res = mv_normality(xd_data_bft, method='hz')\n",
    "            hz_r[freq, tint] = hz_res['HZ']\n",
    "            hz_p[freq, tint] = hz_res['p value']\n",
    "            hz_n[freq, tint] = bool_dict[hz_res['MVN']]\n",
    "\n",
    "            hz_res_c = mv_normality(xd_data_bcft, method='hz')\n",
    "            hz_r_c[freq, tint] = hz_res_c['HZ']\n",
    "            hz_p_c[freq, tint] = hz_res_c['p value']\n",
    "            hz_n_c[freq, tint] = bool_dict[hz_res_c['MVN']]\n",
    "\n",
    "    np.savez(mv_nrm_res_fn, hz_r=hz_r, hz_p=hz_p, hz_n=hz_n, hz_r_c=hz_r_c, hz_p_c=hz_p_c, \\\n",
    "             hz_n_c=hz_n_c)\n",
    "\n",
    "else:\n",
    "    mv_nrm_res = np.load(mv_nrm_res_fn)\n",
    "    hz_r = mv_nrm_res['hz_r']\n",
    "    hz_p = mv_nrm_res['hz_p']\n",
    "    hz_n = mv_nrm_res['hz_n']\n",
    "    hz_r_c = mv_nrm_res['hz_r_c']\n",
    "    hz_p_c = mv_nrm_res['hz_p_c']\n",
    "    hz_n_c = mv_nrm_res['hz_n_c']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952fe331",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = [r'$HZ \\; \\mathrm{statistic}$', r'$p \\; \\mathrm{value}$', 'Normality']\n",
    "row_heatmaps([hz_r, hz_p, hz_n], titles=titles, figsize=(8, 4), share_cbar=False, \\\n",
    "             cbar_loc=None, clip_pctile=1, xlabels='Time bin', ylabel='Frequency channel', \\\n",
    "             yticklabels=plt_chans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6a371c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAD-clipped data\n",
    "titles = [r'$HZ \\; \\mathrm{statistic}$', r'$p \\; \\mathrm{value}$', 'Normality']\n",
    "row_heatmaps([hz_r_c, hz_p_c, hz_n_c], titles=titles, figsize=(8, 4), share_cbar=False, \\\n",
    "             cbar_loc=None, clip_pctile=1, xlabels='Time bin', ylabel='Frequency channel', \\\n",
    "             yticklabels=plt_chans)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f884cbdd",
   "metadata": {},
   "source": [
    "### Interpolation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6469136",
   "metadata": {},
   "source": [
    "#### Visualize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243ad547",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(ncols=2, nrows=2, figsize=(7, 5), sharey='row', sharex='col')\n",
    "\n",
    "axes[0][0].plot(np.abs(xd_gmed_res), alpha=0.7)\n",
    "axes[0][1].plot(np.abs(xd_hmean_res), alpha=0.7)\n",
    "axes[1][0].plot(np.angle(xd_gmed_res), alpha=0.7)\n",
    "axes[1][1].plot(np.angle(xd_hmean_res), alpha=0.7)\n",
    "\n",
    "axes[0][0].set_ylabel(r'$|V|$')\n",
    "axes[1][0].set_ylabel(r'$\\varphi$')\n",
    "\n",
    "axes[1][0].set_xlabel('Frequency channel')\n",
    "axes[1][1].set_xlabel('Frequency channel')\n",
    "\n",
    "axes[0][0].set_title('Geometric Median')\n",
    "axes[0][1].set_title('HERA Mean')\n",
    "\n",
    "for axr in axes:\n",
    "    for axc in axr:\n",
    "        axc.set_xticks(np.arange(plt_chans.size)[::25])\n",
    "        axc.set_xticklabels(plt_chans[::25])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a81ba0",
   "metadata": {},
   "source": [
    "#### Fill in gaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690611e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid interpolation to replace nan values\n",
    "gmed_interp2 = nan_interp2d(xd_gmed_res)\n",
    "hmean_interp2 = nan_interp2d(xd_hmean_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01636d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_chans = extrem_nans(np.isnan(xd_gmed_res).all(axis=1))\n",
    "flt_chans = chans.copy()\n",
    "if nan_chans.size != 0:\n",
    "    flt_chans = np.delete(flt_chans, nan_chans, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2a2c8c",
   "metadata": {},
   "source": [
    "### Power spectrum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6687d76",
   "metadata": {},
   "source": [
    "#### All time integrations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a088eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_resolution = np.median(np.ediff1d(freqs))\n",
    "\n",
    "gmed_delay, gmed_pspec = signal.periodogram(gmed_interp2, fs=1/f_resolution, \\\n",
    "    window='hann', scaling='spectrum', nfft=None, detrend=False, \\\n",
    "    return_onesided=False, axis=0)\n",
    "\n",
    "delay_sort = np.argsort(gmed_delay)\n",
    "gmed_delay = gmed_delay[delay_sort]\n",
    "gmed_pspec = gmed_pspec[delay_sort, :]\n",
    "\n",
    "hmean_delay, hmean_pspec = signal.periodogram(hmean_interp2, fs=1/f_resolution, \\\n",
    "    window='hann', scaling='spectrum', nfft=None, detrend=False, \\\n",
    "    return_onesided=False, axis=0)\n",
    "\n",
    "delay_sort = np.argsort(hmean_delay)\n",
    "hmean_delay = hmean_delay[delay_sort]\n",
    "hmean_pspec = hmean_pspec[delay_sort, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a7ef8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(ncols=3, figsize=(8, 5), sharey=True)\n",
    "\n",
    "axes[0].plot(gmed_delay, gmed_pspec, alpha=0.3)\n",
    "axes[0].plot(gmed_delay, gmed_pspec.mean(axis=1), alpha=1, color='orange')\n",
    "axes[0].set_ylabel('Power spectrum')\n",
    "\n",
    "axes[1].plot(hmean_delay, hmean_pspec, alpha=0.3)\n",
    "axes[1].plot(hmean_delay, hmean_pspec.mean(axis=1), alpha=1, color='purple')\n",
    "\n",
    "axes[2].plot(gmed_delay, gmed_pspec.mean(axis=1), alpha=0.7, color='orange', label='Geometric Median')\n",
    "axes[2].plot(hmean_delay, hmean_pspec.mean(axis=1), alpha=0.7, color='purple', label='HERA Mean')\n",
    "\n",
    "for ax in axes:\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_xlabel('Delay')\n",
    "    \n",
    "axes[0].set_title('Geometric Median')\n",
    "axes[1].set_title('HERA Mean')\n",
    "axes[2].set_title('Comparison')\n",
    "axes[2].legend(loc='best')\n",
    "\n",
    "plt.suptitle('Power spectra')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5638cc6b",
   "metadata": {},
   "source": [
    "#### Cross-power spectrum between neighbouring time bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cbe6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "gmed_interp2_1 = gmed_interp2[:, ::2]\n",
    "gmed_interp2_2 = gmed_interp2[:, 1::2]\n",
    "\n",
    "hmean_interp2_1 = hmean_interp2[:, ::2]\n",
    "hmean_interp2_2 = hmean_interp2[:, 1::2]\n",
    "\n",
    "gmed_delay, gmed_pspec = signal.csd(gmed_interp2_1, gmed_interp2_2, fs=1/f_resolution, \\\n",
    "    window='hann', scaling='spectrum', nfft=None, detrend=False, \\\n",
    "    return_onesided=False, axis=0)\n",
    "\n",
    "delay_sort = np.argsort(gmed_delay)\n",
    "gmed_delay = gmed_delay[delay_sort]\n",
    "gmed_pspec = gmed_pspec[delay_sort, :]\n",
    "\n",
    "hmean_delay, hmean_pspec = signal.csd(hmean_interp2_1, hmean_interp2_2, fs=1/f_resolution, \\\n",
    "    window='hann', scaling='spectrum', nfft=None, detrend=False, \\\n",
    "    return_onesided=False, axis=0)\n",
    "\n",
    "delay_sort = np.argsort(hmean_delay)\n",
    "hmean_delay = hmean_delay[delay_sort]\n",
    "hmean_pspec = hmean_pspec[delay_sort, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81ce392",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(ncols=3, figsize=(8, 5), sharey=True)\n",
    "\n",
    "axes[0].plot(gmed_delay, np.abs(gmed_pspec), alpha=0.3)\n",
    "axes[0].plot(gmed_delay, np.abs(gmed_pspec.mean(axis=1)), alpha=1, color='orange')\n",
    "axes[0].set_ylabel('Power spectrum')\n",
    "\n",
    "axes[1].plot(hmean_delay, np.abs(hmean_pspec), alpha=0.3)\n",
    "axes[1].plot(hmean_delay, np.abs(hmean_pspec.mean(axis=1)), alpha=1, color='purple')\n",
    "\n",
    "axes[2].plot(gmed_delay, np.abs(gmed_pspec.mean(axis=1)), alpha=0.8, color='orange', label='Geometric Median')\n",
    "axes[2].plot(hmean_delay, np.abs(hmean_pspec.mean(axis=1)), alpha=0.8, color='purple', label='HERA Mean')\n",
    "\n",
    "for ax in axes:\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_xlabel('Delay')\n",
    "    \n",
    "axes[0].set_title('Geometric Median')\n",
    "axes[1].set_title('HERA Mean')\n",
    "axes[2].set_title('Comparison')\n",
    "axes[2].legend(loc='best')\n",
    "\n",
    "plt.suptitle('Power spectra')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854b52ad",
   "metadata": {},
   "source": [
    "#### Only average visibilities across days\n",
    "\n",
    "And further average across baselines post power spectrum computation by computing cross-power spectrum across all baseline permutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a7217d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_full_res_fn = os.path.join(res_dir, os.path.basename(xd_vis_file).replace('.npz', '.lst_full_res.npz'))\n",
    "\n",
    "if not os.path.exists(lst_full_res_fn):\n",
    "    xd_gmed_res_bl = np.empty((no_chans, new_no_tints, no_bls), dtype=complex)\n",
    "    xd_hmean_res_bl = np.empty_like(xd_gmed_res_bl)\n",
    "\n",
    "    gmed_ij = None\n",
    "    for bl in range(no_bls):\n",
    "        for freq in range(no_chans):\n",
    "            for tint in range(new_no_tints):\n",
    "                xd_data_bft = xd_data_bls[:, freq, no_bins_agg*tint:no_bins_agg*tint+no_bins_agg, bl].flatten()\n",
    "                if np.isnan(xd_data_bft).all():\n",
    "                    gmed_ft = hmean_ft = np.nan\n",
    "                else:\n",
    "                    gmed_ft = geometric_median(xd_data_bft, init_guess=gmed_ij, \\\n",
    "                                               keep_res=True)\n",
    "                    hmean_ft = rsc_mean(xd_data_bft, sigma=mad_sigma)\n",
    "                xd_gmed_res_bl[freq, tint, bl] = gmed_ft\n",
    "                xd_hmean_res_bl[freq, tint, bl] = hmean_ft\n",
    "                \n",
    "    np.savez(lst_full_res_fn, xd_gmed_res_bl=xd_gmed_res_bl, xd_hmean_res_bl=xd_hmean_res_bl)\n",
    "\n",
    "else:\n",
    "    red_res = np.load(lst_full_res_fn)\n",
    "    xd_gmed_res_bl = red_res['xd_gmed_res_bl']\n",
    "    xd_hmean_res_bl = red_res['xd_hmean_res_bl']\n",
    "    \n",
    "# remove baselines with only nan entries\n",
    "nan_bls = np.where(np.isnan(xd_data_bls).all(axis=(0, 1, 2)))[0]\n",
    "flt_no_bls = no_bls - nan_bls.size\n",
    "xd_gmed_res_bl = np.delete(xd_gmed_res_bl, nan_bls, axis=2)\n",
    "xd_hmean_res_bl = np.delete(xd_hmean_res_bl, nan_bls, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf3e62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the visibility location estimates for a selected time slice\n",
    "fig, axes = plt.subplots(ncols=2, nrows=2, figsize=(7, 5), sharey='row', sharex='col')\n",
    "\n",
    "slct_tint = 0\n",
    "\n",
    "axes[0][0].plot(np.abs(xd_gmed_res_bl[:, slct_tint, :]), alpha=0.7)\n",
    "axes[0][1].plot(np.abs(xd_hmean_res_bl[:, slct_tint, :]), alpha=0.7)\n",
    "axes[1][0].plot(np.angle(xd_gmed_res_bl[:, slct_tint, :]), alpha=0.7)\n",
    "axes[1][1].plot(np.angle(xd_hmean_res_bl[:, slct_tint, :]), alpha=0.7)\n",
    "\n",
    "axes[0][0].set_ylabel(r'$|V|$')\n",
    "axes[1][0].set_ylabel(r'$\\varphi$')\n",
    "\n",
    "axes[1][0].set_xlabel('Frequency channel')\n",
    "axes[1][1].set_xlabel('Frequency channel')\n",
    "\n",
    "axes[0][0].set_title('Geometric Median')\n",
    "axes[0][1].set_title('HERA Mean')\n",
    "\n",
    "for axr in axes:\n",
    "    for axc in axr:\n",
    "        axc.set_xticks(np.arange(plt_chans.size)[::25])\n",
    "        axc.set_xticklabels(plt_chans[::25])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fcedab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D interpolation for each baseline separately\n",
    "gmed_interp_bl_list = []\n",
    "hmean_interp_bl_list = []\n",
    "nan_idxs_f = []\n",
    "nan_idxs_t = []\n",
    "\n",
    "for bl in range(flt_no_bls):\n",
    "    gmed_i, gmed_nidxf, gmed_nidxt = nan_interp2d(xd_gmed_res_bl[..., bl], rtn_nan_idxs=True)\n",
    "    hmean_i, hmean_nidxf, hmean_nidxt = nan_interp2d(xd_hmean_res_bl[..., bl], rtn_nan_idxs=True)\n",
    "    gmed_interp_bl_list.append(gmed_i)\n",
    "    hmean_interp_bl_list.append(hmean_i)\n",
    "    nan_idxs_f.append(gmed_nidxf)\n",
    "    nan_idxs_f.append(hmean_nidxf)\n",
    "    nan_idxs_t.append(gmed_nidxt)\n",
    "    nan_idxs_t.append(hmean_nidxt)\n",
    "    \n",
    "if np.unique(nan_idxs_f).size != 0:\n",
    "    gmed_interp_bl_list = [np.delete(gmed_i, np.unique(nan_idxs_f), axis=0) for gmed_i in gmed_interp_bl_list]\n",
    "    hmean_interp_bl_list = [np.delete(hmean_i, np.unique(nan_idxs_f), axis=0) for hmean_i in hmean_interp_bl_list]\n",
    "    \n",
    "if np.unique(nan_idxs_t).size != 0:\n",
    "    gmed_interp_bl_list = [np.delete(gmed_i, np.unique(nan_idxs_t), axis=1) for gmed_i in gmed_interp_bl_list]\n",
    "    hmean_interp_bl_list = [np.delete(hmean_i, np.unique(nan_idxs_t), axis=1) for hmean_i in hmean_interp_bl_list]\n",
    "    \n",
    "gmed_interp2_bl = np.moveaxis(np.array(gmed_interp_bl_list), 0, 2)\n",
    "hmean_interp2_bl = np.moveaxis(np.array(hmean_interp_bl_list), 0, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee0da03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross-PS between all baseline pairs\n",
    "bl_pairs = list(itertools.permutations(np.arange(flt_no_bls), r=2))\n",
    "bls1 = [i[0] for i in bl_pairs]\n",
    "bls2 = [i[1] for i in bl_pairs]\n",
    "\n",
    "gmed_delay, gmed_pspec = signal.csd(gmed_interp2_bl[..., bls1], gmed_interp2_bl[..., bls2], \\\n",
    "    fs=1/f_resolution, window='hann', scaling='spectrum', nfft=None, detrend=False, \\\n",
    "    return_onesided=False, axis=0)\n",
    "\n",
    "delay_sort = np.argsort(gmed_delay)\n",
    "gmed_delay = gmed_delay[delay_sort]\n",
    "gmed_pspec = gmed_pspec[delay_sort, :]\n",
    "\n",
    "hmean_delay, hmean_pspec = signal.csd(hmean_interp2_bl[..., bls1], hmean_interp2_bl[..., bls2], \\\n",
    "    fs=1/f_resolution, window='hann', scaling='spectrum', nfft=None, detrend=False, \\\n",
    "    return_onesided=False, axis=0)\n",
    "\n",
    "delay_sort = np.argsort(hmean_delay)\n",
    "hmean_delay = hmean_delay[delay_sort]\n",
    "hmean_pspec = hmean_pspec[delay_sort, :]\n",
    "\n",
    "gmed_pspec = np.nanmean(gmed_pspec, axis=2)\n",
    "hmean_pspec = np.nanmean(hmean_pspec, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f31eee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(ncols=3, figsize=(8, 5), sharey=True)\n",
    "\n",
    "axes[0].plot(gmed_delay, np.abs(gmed_pspec), alpha=0.3)\n",
    "axes[0].plot(gmed_delay, np.abs(gmed_pspec.mean(axis=1)), alpha=1, color='orange')\n",
    "axes[0].set_ylabel('Power spectrum')\n",
    "\n",
    "axes[1].plot(hmean_delay, np.abs(hmean_pspec), alpha=0.3)\n",
    "axes[1].plot(hmean_delay, np.abs(hmean_pspec.mean(axis=1)), alpha=1, color='purple')\n",
    "\n",
    "# average over times\n",
    "axes[2].plot(gmed_delay, np.abs(gmed_pspec.mean(axis=1)), alpha=0.6, color='orange', label='Geometric Median')\n",
    "axes[2].plot(hmean_delay, np.abs(hmean_pspec.mean(axis=1)), alpha=0.6, color='purple', label='HERA Mean')\n",
    "\n",
    "for ax in axes:\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_xlabel('Delay')\n",
    "    \n",
    "axes[0].set_title('Geometric Median')\n",
    "axes[1].set_title('HERA Mean')\n",
    "axes[2].set_title('Comparison')\n",
    "axes[2].legend(loc='best')\n",
    "\n",
    "plt.suptitle('Power spectra')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
