{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e795ca4e",
   "metadata": {},
   "source": [
    "<center><strong><font size=+3>Applications of robust 2D median estimators to HERA data</font></center>\n",
    "<br><br>\n",
    "</center>\n",
    "<center><strong><font size=+2>Matyas Molnar and Bojan Nikolic</font><br></strong></center>\n",
    "<br><center><strong><font size=+1>Astrophysics Group, Cavendish Laboratory, University of Cambridge</font></strong></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8102317f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import gridspec\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.axes_grid1.inset_locator import mark_inset, zoomed_inset_axes\n",
    "from scipy.stats.mstats import gmean as geometric_mean\n",
    "\n",
    "from hera_cal.io import HERAData\n",
    "from hera_cal.redcal import get_reds\n",
    "\n",
    "from robstat.plotting import row_heatmaps\n",
    "from robstat.robstat import Cmardia_median, geometric_median, mardia_median, mv_median, \\\n",
    "tukey_median\n",
    "from robstat.stdstat import rsc_mean\n",
    "from robstat.utils import DATAPATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2913fa9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b5f7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_figs = False\n",
    "if plot_figs:\n",
    "    import matplotlib as mpl\n",
    "    mpl.rcParams['figure.dpi'] = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d057f5",
   "metadata": {},
   "source": [
    "### Load HERA visibility data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da7a4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data = os.path.join(DATAPATH, 'zen.2458098.43869.HH.OCRSA.uvh5')\n",
    "\n",
    "hd = HERAData(sample_data)\n",
    "data, flags, _ = hd.read()\n",
    "\n",
    "reds = get_reds(hd.antpos, pols=hd.pols)\n",
    "flat_bls = [bl for grp in reds for bl in grp if bl in data.keys()]\n",
    "reds = [grp for grp in reds if set(grp).issubset(flat_bls)]\n",
    "bl_dict = {k: i for i, k in enumerate(flat_bls)}\n",
    "\n",
    "data = {k: np.ma.array(v, mask=flags[k], fill_value=np.nan) for k, v \\\n",
    "        in data.items()}\n",
    "mdata = np.ma.empty((hd.Nfreqs, hd.Ntimes, hd.Nbls), fill_value=np.nan, \\\n",
    "                     dtype=complex)\n",
    "for i, bl in enumerate(flat_bls):\n",
    "    mdata[..., i] = data[bl].transpose()\n",
    "    \n",
    "data = mdata.filled() # dimensions (freqs, times, bls)\n",
    "flags = mdata.mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bddb601d",
   "metadata": {},
   "source": [
    "### Redundant averaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b775ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "slct_bls = reds[0]\n",
    "slct_bl_idxs = np.array([bl_dict[slct_bl] for slct_bl in slct_bls])\n",
    "slct_data = data[..., slct_bl_idxs]\n",
    "slct_flags = flags[..., slct_bl_idxs]\n",
    "assert slct_flags.sum() == np.isnan(slct_data).sum()\n",
    "print('Looking at baselines redundant to {}'.format(slct_bls[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bfb788",
   "metadata": {},
   "outputs": [],
   "source": [
    "from robstat.utils import decomposeCArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9cad2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at one time integration / frequency slice with high variance\n",
    "idxs = np.unravel_index(np.nanargmax(np.nanstd(slct_data, axis=-1)), \\\n",
    "                        slct_data.shape[:2])\n",
    "print('Selecting freq / time slice {}'.format(idxs))\n",
    "slct_data_slice = slct_data[idxs[0], idxs[1], :]\n",
    "\n",
    "flt_nan = lambda x: x[~np.isnan(x)]\n",
    "sample_gmean = geometric_mean(flt_nan(slct_data_slice))\n",
    "sample_gmed = geometric_median(slct_data_slice, weights=None)\n",
    "sample_tmed = tukey_median(slct_data_slice)['barycenter']\n",
    "sample_mmed = Cmardia_median(slct_data_slice)\n",
    "bad_med = lambda x : np.nanmedian(x.real) + np.nanmedian(x.imag)*1j\n",
    "sample_bmed = bad_med(slct_data_slice)\n",
    "sample_hmean = rsc_mean(slct_data_slice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f25452",
   "metadata": {},
   "outputs": [],
   "source": [
    "med_ests = list(zip([sample_gmean, sample_gmed, sample_tmed, sample_mmed, sample_bmed, sample_hmean], \n",
    "               ['Geometric Mean', 'Geometric Median', 'Tukey Median', 'Mardia Median', \\\n",
    "                'Separate Median', 'HERA Mean']))\n",
    "for me in med_ests:\n",
    "    print('{:17s}: {:4f}'.format(me[1], me[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1669d87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6, 6), dpi=100)\n",
    "\n",
    "ax.scatter(slct_data_slice.real, slct_data_slice.imag, alpha=0.5)\n",
    "ax.plot(sample_gmean.real, sample_gmean.imag, 'ro', label='Geo mean')\n",
    "ax.plot(sample_gmed.real, sample_gmed.imag, 'co', label='Geo med')\n",
    "ax.plot(sample_tmed.real, sample_tmed.imag, 'yo', label='Tukey')\n",
    "ax.plot(sample_mmed.real, sample_mmed.imag, 'ko', label='Mardia')\n",
    "ax.plot(sample_bmed.real, sample_bmed.imag, 'bo', label='Separate')\n",
    "ax.plot(sample_hmean.real, sample_hmean.imag, 'go', label='HERA')\n",
    "\n",
    "ax.annotate(slct_bls[0], xy=(0.05, 0.05), xycoords='axes fraction')\n",
    "ax.set_xlabel(r'$\\mathfrak{Re} \\; (V)$')\n",
    "ax.set_ylabel(r'$\\mathfrak{Im}(V)$')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920f2631",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_int = np.where(~np.isnan(data).all(axis=(0, 2)))[0][0] # first non-nan index\n",
    "# perhaps find index with fewest nans?\n",
    "gmean_res = np.empty((data.shape[0], len(reds)), dtype=complex)\n",
    "gmed_res, tmed_res, mmed_res, bmed_res, hmean_res = [np.empty_like(gmean_res) for _ in range(5)]\n",
    "\n",
    "gmed_ij, mmed_ij = None, None\n",
    "for i, bl_grp in enumerate(reds):\n",
    "    slct_bl_idxs = np.array([bl_dict[slct_bl] for slct_bl in bl_grp])\n",
    "    for j, row in enumerate(data[:, time_int, slct_bl_idxs]):\n",
    "        if np.isnan(row).all():\n",
    "            gmean_ij = gmed_ij = tmed_ij = mmed_ij = bmed_ij = hmean_ij = np.nan\n",
    "        else:\n",
    "            gmean_ij = geometric_mean(flt_nan(row))\n",
    "            gmed_ij = geometric_median(row, weights=None, init_guess=gmed_ij)\n",
    "            tmed_ij = tukey_median(row)['barycenter']\n",
    "            mmed_ij = Cmardia_median(row, init_guess=mmed_ij)\n",
    "            bmed_ij = bad_med(row)\n",
    "            hmean_ij = rsc_mean(row)\n",
    "        gmean_res[j, i] = gmean_ij\n",
    "        gmed_res[j, i] = gmed_ij\n",
    "        tmed_res[j, i] = tmed_ij\n",
    "        mmed_res[j, i] = mmed_ij\n",
    "        bmed_res[j, i] = bmed_ij\n",
    "        hmean_res[j, i] = hmean_ij\n",
    "        \n",
    "med_est_res = list(zip([i[1] for i in med_ests], \\\n",
    "                  [gmean_res, gmed_res, tmed_res, mmed_res, bmed_res, hmean_res]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c7fd2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(constrained_layout=True, figsize=(10, 20), dpi=100)\n",
    "spec = gridspec.GridSpec(nrows=2*len(med_ests), figure=fig, ncols=2)\n",
    "\n",
    "axes = []\n",
    "for i in range(len(med_ests)):\n",
    "    ax1 = fig.add_subplot(spec[i*2:2+i*2, 0])\n",
    "    ax2 = fig.add_subplot(spec[i*2, 1])\n",
    "    ax3 = fig.add_subplot(spec[i*2+1, 1])\n",
    "    axes.append([ax1, ax2, ax3])\n",
    "\n",
    "color = [None for i in med_est_res]\n",
    "for m, med_est in enumerate(med_est_res):\n",
    "    for i, bl_grp in enumerate(range(len(reds))):\n",
    "        axes[m][0].plot(hd.freqs, med_est[1][:, i].real, color=color[m], \\\n",
    "                   label='{}'.format(reds[i][0]) + r' $\\mathfrak{Re}$')\n",
    "        c = axes[m][0].get_lines()[-1].get_color()\n",
    "        color[m] = next(axes[m][0]._get_lines.prop_cycler)['color']\n",
    "        axes[m][0].plot(hd.freqs, med_est[1][:, i].imag, color=c, \\\n",
    "                   label='{}'.format(reds[i][0]) + r' $\\mathfrak{Im}$', ls='--')\n",
    "        axes[m][1].plot(hd.freqs, np.abs(med_est[1][:, i]), color=c, \\\n",
    "                   label='{}'.format(reds[i][0]) + r' $|V|$')\n",
    "        axes[m][2].plot(hd.freqs, np.angle(med_est[1][:, i]), color=c, \\\n",
    "                   label='{}'.format(reds[i][0]) + r' $\\varphi$', ls='--')\n",
    "        axes[m][0].text(x=0.05, y=0.5, s=med_est[0], transform=axes[m][0].transAxes, \\\n",
    "                        fontsize=10, style='normal', weight='light')\n",
    "\n",
    "for ax in axes:\n",
    "    ax[0].set_ylabel(r'$V$')\n",
    "    \n",
    "for ax in axes[-1]:\n",
    "    ax.set_xlabel(r'$\\nu$')\n",
    "    \n",
    "axes[0][0].set_title('Cartesian')\n",
    "axes[0][1].set_title('Polar')\n",
    "\n",
    "for ax in axes[0]:\n",
    "    ax.legend(framealpha=0.5, loc=1)\n",
    "\n",
    "plt.suptitle('Median estimates for 14-m EW baselines')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8820193a",
   "metadata": {},
   "source": [
    "### LST + redundant averaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4693d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_xd_data = np.load(os.path.join(DATAPATH, 'xd_vis.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a809ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "xd_data = sample_xd_data['data'] # dimensions (days, freqs, times, bls)\n",
    "xd_flags = sample_xd_data['flags']\n",
    "xd_data[xd_flags] = np.nan\n",
    "\n",
    "xd_redg = sample_xd_data['redg']\n",
    "xd_times = sample_xd_data['times']\n",
    "xd_freqs = sample_xd_data['chans']\n",
    "xd_days = sample_xd_data['days']\n",
    "xd_pol = sample_xd_data['pol'].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c7aa44",
   "metadata": {},
   "outputs": [],
   "source": [
    "slct_bl_idxs = np.where(xd_redg[:, 0] == 0)[0]\n",
    "data = xd_data[..., slct_bl_idxs]\n",
    "flags = xd_flags[..., slct_bl_idxs]\n",
    "slct_red_bl = xd_redg[slct_bl_idxs[0], :][1:]\n",
    "print('Looking at baselines redundant to ({}, {}, \\'{}\\')'.\\\n",
    "      format(*slct_red_bl, xd_pol))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198a3555",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at 2 consecutive time integrations / 1 frequency slice with high variance\n",
    "idxs = np.unravel_index(np.nanargmax(np.nanstd(data[..., :-1, :], axis=(0, -1))), \\\n",
    "                        data.shape[1:-1])\n",
    "print('Selecting freq / %time slice: ({}, {}-{})'.format(idxs[0], idxs[1], idxs[1]+1))\n",
    "\n",
    "# Have visibilities across days for the same baseline - can flatten\n",
    "# the data array and perform statistics on the whole dataset\n",
    "data_slice = data[:, idxs[0], idxs[1]:idxs[1]+2, :].flatten()\n",
    "\n",
    "xd_sample_gmean = geometric_mean(flt_nan(data_slice))\n",
    "xd_sample_gmed = geometric_median(data_slice, weights=None)\n",
    "xd_sample_tmed = tukey_median(data_slice)['barycenter']\n",
    "xd_sample_mmed = Cmardia_median(data_slice)\n",
    "xd_sample_bmed = bad_med(data_slice)\n",
    "xd_sample_hmean = rsc_mean(data_slice)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f05842",
   "metadata": {},
   "source": [
    "Alternatively, we could take the median of the visibility amplitude and the Mardia median of the phase. While this is an improvement on doing the median on cartesian coordinates separately, it still does not wholly consider the complex data. The geometric median or the Tukey median would be preferable methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb1508f",
   "metadata": {},
   "outputs": [],
   "source": [
    "med_ests = list(zip([xd_sample_gmean, xd_sample_gmed, xd_sample_tmed, xd_sample_mmed, \\\n",
    "                     xd_sample_bmed, xd_sample_hmean], \\\n",
    "               ['Geometric Mean', 'Geometric Median', 'Tukey Median', 'Mardia Median', \\\n",
    "                'Separate Median', 'HERA Mean'], \\\n",
    "               ['ro', 'co', 'yo', 'ko', 'bo', 'go']))\n",
    "for me in med_ests:\n",
    "    print('{:17s}: {:4f}'.format(me[1], me[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158f271e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6, 6), dpi=100)\n",
    "\n",
    "ax.scatter(flt_nan(data_slice).real, flt_nan(data_slice).imag, alpha=0.5)\n",
    "for i, med_est in enumerate(med_ests):\n",
    "    ax.plot(med_est[0].real, med_est[0].imag, med_est[2], label=med_est[1])\n",
    "\n",
    "# zoomed in sub region of the original image\n",
    "axins = zoomed_inset_axes(ax, zoom=6, loc=4)\n",
    "axins.scatter(flt_nan(data_slice).real, flt_nan(data_slice).imag, alpha=0.5)\n",
    "for i, med_est in enumerate(med_ests):\n",
    "    axins.plot(med_est[0].real, med_est[0].imag, med_est[2])\n",
    "\n",
    "x1 = np.floor(np.min([i[0].real for i in med_ests[:-2]]))\n",
    "x2 = np.ceil(np.max([i[0].real for i in med_ests[:-2]]))\n",
    "y1 = np.floor(np.min([i[0].imag for i in med_ests[:-2]]))\n",
    "y2 = np.ceil(np.max([i[0].imag for i in med_ests[:-2]]))\n",
    "axins.set_xlim(x1, x2)\n",
    "axins.set_ylim(y1, y2)\n",
    "\n",
    "axins.tick_params(axis='x', direction='in', pad=-15)\n",
    "mark_inset(ax, axins, loc1=1, loc2=3, fc='none', ec='0.5')\n",
    "\n",
    "ax.annotate(tuple(slct_red_bl) + (str(xd_pol),), xy=(0.05, 0.05), \\\n",
    "            xycoords='axes fraction')\n",
    "ax.set_xlabel(r'$\\mathfrak{Re} \\; (V)$')\n",
    "ax.set_ylabel(r'$\\mathfrak{Im}(V)$')\n",
    "\n",
    "ax.legend(loc=1, prop={'size': 10})\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448a3965",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.jointplot(x=flt_nan(data_slice).real, y=flt_nan(data_slice).imag, \\\n",
    "                  kind='kde', height=9, cmap='Blues', fill=True, space=0)\n",
    "g.set_axis_labels(r'$\\mathfrak{Re} \\; (V)$', r'$\\mathfrak{Im}(V)$', size=14)\n",
    "for i, med_est in enumerate(med_ests):\n",
    "    g.ax_joint.plot(med_est[0].real, med_est[0].imag, med_est[2], label=med_est[1])\n",
    "legend_properties = {'size': 12}\n",
    "g.ax_joint.legend(prop=legend_properties, loc='upper right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27bec739",
   "metadata": {},
   "outputs": [],
   "source": [
    "xd_gmean_res = np.empty((*xd_data.shape[1:3], len(reds)), dtype=complex)\n",
    "xd_gmed_res, xd_tmed_res, xd_mmed_res, xd_bmed_res, xd_hmean_res = [np.empty_like(xd_gmean_res) \\\n",
    "                                                                    for _ in range(5)]\n",
    "gmed_ij, mmed_ij = None, None\n",
    "for i, bl_grp in enumerate(reds):\n",
    "    slct_bl_idxs = np.array([bl_dict[slct_bl] for slct_bl in bl_grp])\n",
    "    xd_data_b = xd_data[..., slct_bl_idxs]\n",
    "    for freq in range(xd_data_b[:2].shape[1]):\n",
    "        for tint in range(xd_data_b[:2].shape[2]):\n",
    "            xd_data_bft = xd_data_b[:, freq, tint, :].flatten()\n",
    "            if np.isnan(xd_data_bft).all():\n",
    "                gmean_ij = gmed_ij = tmed_ij = mmed_ij = bmed_ij = hmean_ij = np.nan\n",
    "            else:\n",
    "                gmean_ij = geometric_mean(flt_nan(xd_data_bft))\n",
    "                gmed_ij = geometric_median(xd_data_bft, weights=None, init_guess=gmed_ij)\n",
    "                tmed_ij = tukey_median(xd_data_bft)['barycenter']\n",
    "                mmed_ij = Cmardia_median(xd_data_bft, init_guess=mmed_ij)\n",
    "                bmed_ij = bad_med(xd_data_bft)\n",
    "                hmean_ij = rsc_mean(xd_data_bft)\n",
    "            xd_gmean_res[freq, tint, i] = gmean_ij\n",
    "            xd_gmed_res[freq, tint, i] = gmed_ij\n",
    "            xd_tmed_res[freq, tint, i] = tmed_ij\n",
    "            xd_mmed_res[freq, tint, i] = mmed_ij\n",
    "            xd_bmed_res[freq, tint, i] = bmed_ij\n",
    "            xd_hmean_res[freq, tint, i] = hmean_ij"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148ab985",
   "metadata": {},
   "outputs": [],
   "source": [
    "bl_grp = 0\n",
    "arrs = [arr[..., bl_grp] for arr in (xd_gmed_res, xd_tmed_res, xd_bmed_res, xd_hmean_res)]\n",
    "\n",
    "row_heatmaps(arrs, apply_np_fn='abs', clip_pctile=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ff9dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_heatmaps(arrs, apply_np_fn='angle', vmin=-np.pi, vmax=np.pi, center=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94099fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_heatmaps(arrs, apply_np_fn='real')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8fa5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_heatmaps(arrs, apply_np_fn='imag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88e188b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# find rmeds for all freqs and times separately - heatmap time and freq? check smootheness\n",
    "# recreate the LST-Bin averaging process - sigma_clip about mean? \n",
    "# literature on median of median?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a0f26b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
